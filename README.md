# Podcast Sponsorblocker API

Ein Web-Server, der Werbesegmente in Podcast-Episoden automatisch erkennt und markiert.

## Features

- ðŸŽ™ï¸ Automatischer Download von Podcast-Episoden via URL
- ðŸ“ Organisierte Dateistruktur: `downloads/Podcast/Episode/`
- ðŸŽ¯ Transkription mit OpenAI Whisper (inkl. Timestamps)
- ðŸ¤– KI-gestÃ¼tzte Erkennung von Werbesegmenten mit GPT-4
- ðŸ’¾ SQLite-Datenbank fÃ¼r Caching (gleiche URL = sofortige Antwort)
- ðŸ“ Persistente Speicherung von Transkripten und GPT-Responses
- ðŸš€ REST API mit Express.js
- âœ‚ï¸ Automatisches Audio-Splitting fÃ¼r groÃŸe Dateien (>25MB)

## Installation

1. **Dependencies installieren:**
```bash
npm install
```

2. **FFmpeg installieren** (benÃ¶tigt fÃ¼r Audio-Splitting):
```bash
# macOS
brew install ffmpeg

# Ubuntu/Debian
sudo apt-get install ffmpeg

# Windows
# Download von https://ffmpeg.org/download.html
```

3. **Umgebungsvariablen konfigurieren:**
```bash
cp .env.example .env
```

Dann `.env` editieren und deinen OpenAI API Key eintragen:
```
OPENAI_API_KEY=sk-...
PORT=3000
OPENAI_MODEL=gpt-4-turbo
```

## Verwendung

### Server starten

```bash
npm start
```

Oder fÃ¼r Development mit Auto-Reload:
```bash
npm run dev
```

### API Endpoints

#### `GET /analyze?url=<podcast_url>`

Analysiert eine Podcast-Episode und gibt Werbesegmente zurÃ¼ck.

**Beispiel:**
```bash
curl "http://localhost:3000/analyze?url=https://example.com/podcast.mp3"
```

**Response:**
```json
{
  "cached": false,
  "url": "https://example.com/podcast.mp3",
  "title": "podcast.mp3",
  "segments": [
    {
      "start_ms": 754000,
      "end_ms": 912000,
      "category": "werbung",
      "description": "Sponsoren-ErwÃ¤hnung von ProductX"
    }
  ]
}
```

Bei wiederholten Anfragen mit derselben URL wird `cached: true` zurÃ¼ckgegeben und das Ergebnis kommt direkt aus der Datenbank (ohne erneutes Processing).

#### `GET /health`

Health-Check Endpoint.

#### `GET /`

API-Dokumentation.

## Workflow

1. **URL-Check:** PrÃ¼ft, ob die Podcast-URL bereits in der DB existiert
2. **Download:** Falls nicht gecacht, wird die Episode heruntergeladen
   - Erstellt Ordnerstruktur: `downloads/PodcastName/EpisodeName/`
3. **Audio-Splitting:** GroÃŸe Dateien (>25MB) werden in 10-Minuten-Chunks aufgeteilt
4. **Transkription:** Audio wird mit Whisper transkribiert (mit Timestamps)
   - Speichert Transkript als `transcript_timestamped.txt` im Episode-Ordner
5. **Analyse:** GPT-4 analysiert das Transkript und identifiziert Werbesegmente
   - Speichert GPT-Response als `ad_detection_response.txt` im Episode-Ordner
6. **Cleanup:** MP3-Dateien werden gelÃ¶scht, Transkripte bleiben erhalten
7. **Speicherung:** Ergebnisse werden in SQLite gespeichert
8. **Response:** JSON mit allen gefundenen Werbesegmenten

## Dateistruktur

Nach der Verarbeitung:

```
downloads/
â””â”€â”€ PodcastName/
    â””â”€â”€ EpisodeName/
        â”œâ”€â”€ transcript_timestamped.txt      # VollstÃ¤ndiges Transkript mit Zeitstempeln
        â”œâ”€â”€ EpisodeName_chunk0_transcript_timestamped.txt  # Chunk-Transkripte
        â”œâ”€â”€ EpisodeName_chunk1_transcript_timestamped.txt
        â””â”€â”€ ad_detection_response.txt       # GPT-4 Analyse-Ergebnis
```

MP3-Dateien werden nach der Verarbeitung automatisch gelÃ¶scht.

## Projektstruktur

```
.
â”œâ”€â”€ server.js                       # Express Server & Hauptlogik
â”œâ”€â”€ database.js                     # SQLite Datenbankfunktionen
â”œâ”€â”€ download.js                     # Podcast Download mit Ordnerstruktur
â”œâ”€â”€ split-audio.js                  # Audio-Splitting fÃ¼r groÃŸe Dateien
â”œâ”€â”€ transcribe.js                   # Whisper API Integration
â”œâ”€â”€ detect-ads.js                   # GPT-4 Werbesegment-Erkennung
â”œâ”€â”€ transcribe-remaining-chunks.js  # Manuelles Transkript-Tool
â”œâ”€â”€ package.json
â”œâ”€â”€ .env.example
â”œâ”€â”€ podcasts.db                     # SQLite Datenbank
â”œâ”€â”€ downloads/                      # Transkripte und Analysen
â””â”€â”€ README.md
```

## Technologie-Stack

- **Node.js** mit ES Modules
- **Express.js** fÃ¼r den Web-Server
- **sql.js** fÃ¼r die SQLite-Datenbank
- **OpenAI API** (Whisper + GPT-4)
- **Axios** fÃ¼r HTTP-Requests
- **FFmpeg** fÃ¼r Audio-Splitting

## Manuelle Transkription

Falls einzelne Chunks manuell transkribiert werden sollen:

```bash
node transcribe-remaining-chunks.js
```

Dieses Script transkribiert verbleibende Chunks und erstellt ein vollstÃ¤ndiges Transkript.

## Hinweise

- **Audio-Dateien:** Werden nach der Verarbeitung automatisch gelÃ¶scht (nur Transkripte bleiben)
- **Transkripte:** Werden dauerhaft im `downloads/` Ordner gespeichert
- **Audio-Splitting:** GroÃŸe Dateien werden automatisch in 10-Minuten-Chunks aufgeteilt
- **Chunk-GrÃ¶ÃŸe:** Chunks werden auf 16kHz mono komprimiert (~5MB pro 10 Minuten)
- **Genauigkeit:** HÃ¤ngt von der QualitÃ¤t der Transkription und dem GPT-4 Prompt ab

## Kosten

Die Nutzung verursacht Kosten bei OpenAI:
- **Whisper:** ~$0.006 pro Minute Audio
- **GPT-4 Turbo:** ~$0.01 pro 1K Input-Tokens (abhÃ¤ngig von TranskriptlÃ¤nge)

Beispielrechnung fÃ¼r 60-minÃ¼tige Episode:
- Whisper: 60 Ã— $0.006 = $0.36
- GPT-4: ~$0.05 - $0.15 (je nach TranskriptlÃ¤nge)
- **Total:** ~$0.41 - $0.51 pro Episode

Durch das Caching werden wiederholte Anfragen kostenlos aus der DB beantwortet.

## Umgebungsvariablen

- `OPENAI_API_KEY`: Dein OpenAI API Key (erforderlich)
- `PORT`: Server-Port (Standard: 3000)
- `OPENAI_MODEL`: GPT-Modell fÃ¼r Ad-Detection (Standard: gpt-4-turbo)

## Entwicklung

**Dependencies neu installieren:**
```bash
npm install
```

**Server im Dev-Modus starten:**
```bash
npm run dev
```

**Datenbank zurÃ¼cksetzen:**
```bash
rm podcasts.db
```

## Feature Requests

### `hinweis_timestamp` â€“ Gezieltes Transkribieren ab einem Hinweis-Zeitstempel

**Motivation:**
Aktuell wird immer die gesamte Episode transkribiert, bevor die Werbesegment-Analyse stattfindet. Das ist teuer und langsam. Manchmal ist aber bereits bekannt, *wo* in der Folge eine Werbung oder ein verdÃ¤chtiger Abschnitt beginnt â€“ z. B. Ã¼ber Community-Meldungen, einen externen Hinweis oder einen einfachen Zeitstempel aus einer anderen Quelle.

**Beschreibung:**
Der `/analyze`-Endpoint soll um den optionalen Parameter `hinweis_timestamp` erweitert werden:

```
GET /analyze?url=<podcast_url>&hinweis_timestamp=<sekunden>
```

Ist `hinweis_timestamp` gesetzt, Ã¤ndert sich der Verarbeitungs-Workflow wie folgt:

1. **Download:** Die gesamte Episode wird heruntergeladen (keine Ã„nderung).
2. **Audio-Schnitt:** Aus der heruntergeladenen Datei wird **nur** das Segment
   `[hinweis_timestamp âˆ’ 60s, hinweis_timestamp + 60s]` (Â± 1 Minute) ausgeschnitten.
3. **Transkription:** Nur dieses 2-Minuten-Fenster wird an Whisper geschickt.
4. **Analyse:** Nur das Transkript dieses Fensters wird an GPT-4 zur Werbesegment-Erkennung gesendet.
5. **Response:** Wie bisher â€“ gefundene Segmente als JSON, aber mit `hinweis_timestamp`-Kontext.

**Vorteile:**
- Deutlich geringere Kosten (Whisper + GPT-4 nur fÃ¼r ~2 Minuten statt 60+)
- Deutlich schnellere Antwortzeit
- NÃ¼tzlich, wenn ein Nutzer oder eine externe Quelle schon einen konkreten Verdachtszeitpunkt liefert

**Beispiel-Request:**
```bash
curl "http://localhost:3000/analyze?url=https://example.com/podcast.mp3&hinweis_timestamp=1830"
```
â†’ Transkribiert und analysiert nur den Bereich von 00:29:30 bis 00:31:30.

**Zu klÃ¤ren / Offene Punkte:**
- Einheit des Parameters: Sekunden (Integer) oder `HH:MM:SS`?
- Verhalten, wenn der Timestamp nahe am Anfang/Ende der Folge liegt (Clipping-Handling)
- Soll das Ergebnis separat gecacht werden (eigener DB-Key `url + hinweis_timestamp`)?
- Soll ein partielles Transkript neben dem vollstÃ¤ndigen Transkript gespeichert werden?
